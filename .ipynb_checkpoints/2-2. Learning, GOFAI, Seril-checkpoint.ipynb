{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative VS Quantitative Learning ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Quantitative\n",
    "    * Learn a lot, use the same function to learn words\n",
    "* Qualitative\n",
    "    * Learning specifics, if you want to learn a number you need a different function\n",
    "    * Change in Content in terms of competence; which functions can you use?\n",
    "        * Change in formal system\n",
    "        * What is the Problem here?\n",
    "            * You cannot derive stronger logic from weaker logic\n",
    "                * EX) Cannot computationally produce mobile logic from predicate logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Problem with Qualitative Learning - Cannot derive strong logic from weak logic ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GOFI point of view - 0 dismissal of development\n",
    "    * Qualitative Sense\n",
    "    * These must all be wrong\n",
    "        * The kids already had this built in.\n",
    "    * All cognitive processes are computational?\n",
    "        * There is a possibility that there is cognitive development that isn't driven computationally\n",
    "    * Implies there is no qualitative development\n",
    "        * If there is, GOFI is wrong\n",
    "    * However, there IS computational cognitive development\n",
    "    * There must be cogsci process which is not computational, responsible for qualitative development\n",
    "* Nodes may be affected by the network but may not affect the network itself.\n",
    "    * Which node best tracts the error in the network?\n",
    "    * Alignment, minimisation\n",
    "        * Generate nodes, kill off  → repeat the cycle\n",
    "        * This is the cascade correlational model\n",
    "    * Success\n",
    "        * Identity → additional strategy → Multiple/Division Strategy\n",
    "            * Showed the development as kids do\n",
    "            * Not negligible\n",
    "            * Reasonably Plausible to have Cognitive Development\n",
    "            * Generation of Nodes \n",
    "    * Limitations\n",
    "        * Explanation of Qualitative development\n",
    "        * What is the relation between cognition and language and language processing?\n",
    "    * Computational cognition is defended\n",
    "        * cognition is language-like is defended by floyd\n",
    "        * Inherently language like\n",
    "    * Syntactic Structure\n",
    "        * Words are associated with each other\n",
    "        * Temporal\n",
    "        * You can make a network do a certain task but it does not have syntactic relations\n",
    "            * Compose a formal system on neural networks\n",
    "            * Relies on a language-like predication\n",
    "    * Can Neural Network be systematic?\n",
    "        * Deep learning\n",
    "        * Deep connection between prediction and tracking causation\n",
    "* When do I have strong AI?\n",
    "    * Vervaeke says, I don't know\n",
    "        * If i don't have a criteria of way of understanding, distinguishing between principle, how well am i doing on a scientific project?\n",
    "    * Standard?\n",
    "        * Question that has not been answered → leads to the criterion of the cognitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary ###\n",
    "Problem with Qualitative Learning - Cannot derive strong logic from weak logic. <br>\n",
    "\n",
    "GOFAI does not capture that cog developments could be non-computational.<br>\n",
    "\n",
    "In neural networks, nodes generate and kill off and repeat itself, which is the cascade correlational model.<br>\n",
    "Cascade-Correlation begins with a minimal network, then automatically trains and adds new hidden units one by one.<br> \n",
    "\n",
    "Creating a multi-layer structure. Once a new hidden unit has been added to the network, its input-side weights are frozen.<br>\n",
    "\n",
    "The success of the cascade correlation model was that showed a multiple division strategy.<br>\n",
    "\n",
    "It learns very quickly, the network determines its own size and topology, it retains the structures it has built even if the training set changes, and it requires no back-propagation of error signals through the connections of the network.<br>\n",
    "However, it does not provide the explanation behind the relation of cognition being language like.<br>\n",
    "\n",
    "Syntactic structure is possible as you can make a network do a certain task, but it does nothave syntactic relations. It is language-like.<br>\n",
    "\n",
    "What is the standard of having Strong AI? We don't know, which is where criteron of the cognitve problem arise.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General issue - GOFI and connectionism ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary ###\n",
    "Turing Test to resolve assimilation problem in getting STRONG AI fails because don't know the factors we are using to compare two different things. Langiuage is not a medium that cognition operates. We must do turing test on explicit psychology.\n",
    "\n",
    "This means, we need to measure a machine's competence, such that it is able to preform multiple tasks, rather than simple communication. While being capable of accomplishing multiple tasks, it needs to be able to \"compete\", such that it can accomplish a certain thing at a certain degree.\n",
    "\n",
    "Even if we do measure its competence, it is not enough. We cannot assume that this measured competence is something we can use. We may have a measured procedure but it could be probably not the way how we use competence. The way we use competence could be different than the machine using competence. Therefore, the Turing Test is flawed and needs revision.\n",
    "\n",
    "Therefore, we cannot use materialistic familiarity testing as this causes problems. The reason why GOFAI failed was because it tries to resolve the problem by finding the operators and defining a formal equivilance to resolve the assimilation problem. It runs the turing test on your intuition which is not what we want.\n",
    "\n",
    "GOFAI Extended - It failed not because of the wrong picture, but due to its methology of turning into science. Natural sciences such as physics is not a machine. What GOFAI does is when we find a river with a faucet in a hypothetical west world, it concludes every other river has a faucet, which is ridiculous. Natural scientific aspects do not have logic. GOFAI tries to apply logic on these, which is clearly flawed.\n",
    "\n",
    "For instance, GOFAI does not have the criterion of the cognitive. Natural sciences such as physics or nature have a fundamental ontology, whereas GOFAI does not have it. Since we do not have an established commonground of the cognitive, we could make assumptions. This is why GOFAI does not work.\n",
    "\n",
    "Due to the above, we only end up with WEAK AI.\n",
    "\n",
    "So how do we find the criterion of the cognitive? We need to categorise things that we may put it into science. We need to make the category have an essence so that it supports powerful generalisations, as you cant have science without it. Therefore, things need to be stable over time and attributative to human beings, as well as the elements being existentially relevant. For instance, Money is money because we named it so and everybody uses it such way. There is no scientific intuition behind it. It is what it is. It has its own existential essence.\n",
    "\n",
    "If really really wanted to come up with the criterion of the cognitive without an essence, it is plausible that we might need a theory of relevance realisibility ratherthan just a theory of relevance. According to Steve Hardnard, we can just create a scale of the criterion, take out things that are too weak/too strong and we will end up with the moderate ones, which result in the criterion of the cognitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steve Harnard Extended: Why the Turing Test Fails ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harnard Turing Test EXTENDED: It fails because it cannot resolve the simple grounding problem. According to John Seril's Chinese room argument, even the conversation between the man and the computer is going on in chinese, the man is only doing so because it memorised the book in chinese. It is interacting robotically, rather accordingly. Putting this in a robot, the same things happen.\n",
    "\n",
    "**** Simple Grounding problem: How words (symbols) get their meanings, and hence to the problem of what meaning itself really is ****\n",
    "\n",
    "OBJECTION: What about we have a Virtual Machine?\n",
    "\n",
    "If we have a virtual machine such that the homunculus does memorise all the expressions and reactions in Chinese, we may see that this satisfies the multiple realisibility. As the machine is defined by the man's functions, we have multiple realisibility, which is not something explainable in natural sciences, which we may say that it is an attributed properpty, rather intrinsic. As functions are attributed but minds are not, AI cannot be in terms of mind as AI is asstributive and mind is intrinsic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assimilation Problem of GOFAI ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GOFAI was not correct\n",
    "    * Chris Green\n",
    "    * Determine artifacts - criterion of the physical/cognitive\n",
    "        * whether something is produlent simulation that would be explainable isn't measurable due to lack of the criterion of the cognitive\n",
    "* Kukla\n",
    "    * Need to cut to its joints to do science to have the criterion of the cognitive\n",
    "        * Create categories with systematic import\n",
    "            * Is not just simple tautology\n",
    "            * Categories with relevance do not have systematic import\n",
    "* Frame Problem\n",
    "    * Relevance Problem\n",
    "        * Analysis keep floundering into homuncularity\n",
    "        * Carving in the mind keeps failing due to the above\n",
    "    * A methodological analysis\n",
    "        * Toy modelling --> Microworlds\n",
    "        * Turing Test\n",
    "            * Harnard → Simple Grounding problem\n",
    "                * Chinese room argument\n",
    "            * John Seril\n",
    "                * The whole rooms chinese(man memorises the whole book)\n",
    "                    * Not responding autonomously\n",
    "                * Virtual Machines contains multiple realisability\n",
    "                    * Could be identify with ontology - These are attributed\n",
    "                * Minds must be intrinsic\n",
    "                    * Minds are the entities that do attributions\n",
    "                        * If minds are not intrinsic you have an infinitely regressive attribution\n",
    "* Total Turing Test\n",
    "    * Vervaeke\n",
    "        * Seril’s argument is too focus in objectification\n",
    "            * Natures are patterns like formal system but they are self-organising systems\n",
    "    * Kukla \n",
    "        * We cannot have a theory of relevance\n",
    "    * Darwin\n",
    "        * Found Fittedness\n",
    "        * If evolution is explainable with fittedness, there is no reason we cannot develop a theory of relevance with cognitive evolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seril - EXTENDED ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Seril - Neuromimetic Test\n",
    "    * You have to have something that mimics the brain very similarly in order to have cognition\n",
    "        * Not a clear development causal powers in between the nodes and the neurons\n",
    "        * An alternative for an organic brain is “the organic brain”\n",
    "            * Biochemically organically relevantly identical to the Brain is needed for Cognition\n",
    "* Harnard\n",
    "    * The brain only works as a certain temperature - they take a distinct amount of space\n",
    "         * It is hard to see why those causal factors are relevant to cognitive entity\n",
    "            * It is plausible, but there are many causal features of the brain that are simply contingent due to evolution\n",
    "                * Evolution could go in different biochemical ways, and yet just as cognitive as we are\n",
    "            * It contains too many identities to make a plausible case that are relevant to our brain when producing intelligence and consciousness\n",
    "* Quantum Identity - Consciousness is a quantum effect\n",
    "    * Humans are not quantum computers\n",
    "        * Quantum computation is weak AI since it will fail to explain how to perform a task(will fail be to be strong AI)\n",
    "            * Will lack salience\n",
    "                * Systems dependent on Quantum computations will not have these traits\n",
    "    * Consciousness and quantum does not have any good evidence to be explainable\n",
    "    * Some evidence → does not explain the other evidences which we haven't found → bad argument to say that Brain is quantum\n",
    "* Filtering out too strong or too weak will give us the Criterion of the cognitive\n",
    "    * Hardnard is right?\n",
    "    * Irrelevant?\n",
    "    * Passing the turing test → cognitive agent → criterion of cognitive\n",
    "        * Irrelevant because it is not giving us something we want - carve nature out of the joints\n",
    "        * Methodologically incapable \n",
    "    * Intelligence = OF/CF\n",
    "        * What are the variables here and how do they work rather than just plugging in variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
