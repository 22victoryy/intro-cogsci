{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Memory: levels of processing, retrieval context, transfer appropriate processing, \n",
    "* Attention: transparency opacity\n",
    "* Levels of processing\n",
    "    * 1. Simple understanding: do not need to know meaning or sound \n",
    "    * 2. Minimal understanding, enough to process sound without meaning \n",
    "    * 3. Understanding fully = both sound and meaning \n",
    "        * Retrieval context: the context under which we retrieve memory affects how it is retrieved (THE broken headlight vs A broken headlight) Transfer appropriate processing: storing information in a way that has multi-aptness so it can be used in multiple situations\n",
    "* Problem Solving: insight problem, Gestaltist vs search-inference, combinatorially explosive, well defined vs ill-defined problems\n",
    "    * General problem solver: problem formulation, algorithms vs heuristics\n",
    "    * Psych Literature: Weisberg & Alba, Newell & Simon\n",
    "* Insight Problem Solving:  \n",
    "    * Problem formulation/framing\n",
    "    * Well-formed vs ill-formed problems\n",
    "    * Interconnectivity\n",
    "    * Gestalt: Perceptual restructuring\n",
    "* AI: strong vs weak AI, cognition as computation (Hobbes), GOFAI, digital system, medium independence & multiple realizability, primary vs secondary qualities (Descartes), Aristotle, tokens & types\n",
    "* Hobbes vs Descartes:\n",
    "    * Hobbes = cognition as computation - the mind can be recreated\n",
    "    * Descartes = primary qualities: mathematical brain functions / objective vs secondary qualities: qualia / subjective - the mind cannot be recreated \n",
    "    * Brain vs mind: brain = hardware vs mind = software\n",
    "* Types of AI\n",
    "    * Strong AI: Explaining the mind through attempting to create mind.\n",
    "        * Reverse engineering problems?\n",
    "    * Weak AI: Machines that function for humans. Their functional ability displays things that previously, only humans were capable of doing.\n",
    "* Multiple realizability: A formal system’s ability to function in different physical media - Hobbes’ stance\n",
    "    * Medium independent and formally equivalent\n",
    "    * Medium Independence\n",
    "        * A system to distinguish tokens and reliably manipulate them, regardless of what the physical tokens are.\n",
    "            * Even if I throw away my queen while playing chess and place a nickel instead, as long as I define my nickel as a queen, I have no problems playing chess.\n",
    "        * Multiple realizability, in the philosophy of mind, is the thesis that the same mental property, state, or event can be implemented by different physical properties, states, or events.\n",
    "    * Formal Equivalence \n",
    "        * For each distinct position in one system, there is exactly one corresponding position in the other system.\n",
    "        * Whenever a move is legal in one system, the corresponding move in the other system is also legal.\n",
    "        * All starting positions correspond.\n",
    "    * Combinatorial Explosion (CE): Dictates that even for simple problems, they have enormous search spaces that make checking each possibility impossible.\n",
    "        * This happens mainly trying to implement an algorithm rationally rather heuristically, which is the main reason why we are failing to implement Strong AI aside from the live organism identity problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Intelligence ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Descartes - “purely material machine will not be capable of reasoning because it is purely mechanical. It cannot consider about enumerative standards, truth, and meaning.”\n",
    "    *  “The core of what you are is consciousness and rationality\n",
    "    * Core to your personhood → Cannot be captured by material methods\n",
    "    * Does not satisfy the Naturalistic imperative → Does not explain how and why we generate scientific generations\n",
    "        * A significant minority believe that Descartes is still taken seriously in important ways\n",
    "        * Many people argue that the only way to solve this problem will require some fundamental changes in the scientific field\n",
    "            * Existentially/Philosophical significance?\n",
    "        * AI → Self-interpretation(spiritual sensibility)\n",
    "* GOFAI: Good Old Artificial Intelligence - Symbolic AI\n",
    "    * A Hobbesian approach of AI\n",
    "        * Information is encoded in propositions(proposing truth) as in abstract and symbolic nature such as in Coding\n",
    "        * Propositions are manipulated in a logical, mathematical fashion\n",
    "    * A computer is an interpreted automatic Formal system\n",
    "        * Components of a formal system\n",
    "            * Rules\n",
    "            * Manipulating tokens\n",
    "            * INTEGRATE FORMALLY → Formal System\n",
    "             * EX) Monopoly\n",
    "                * Money → Tokens\n",
    "                * Alter or replace a token\n",
    "                    * lose some houses and put a hotel, get a new property, giving money to others\n",
    "                * Configuration of tokens\n",
    "                    * Ex) What the dice says, the rules that correspond to such. What is a legal move and what is an illegal move is determined by the dice and the system. You can’t go 4 steps if you rolled a 3.\n",
    "                * INTEGRATE → Monopoly\n",
    "        * Every little aspect meaning in a formal system is irrelevant\n",
    "            * This is because All I have to know are the functions of the tokens and the rules of the setting to run the system.\n",
    "            * EXII) Chess\n",
    "                * Tokens, token relations\n",
    "                    * The new configurations allows new rules to be applied and how tokens are moved and it just keeps going on \n",
    "                    * This makes a formal system, the system runs on this way of its own\n",
    "                    * We don’t need to know what each token stands for but how they relate to each other and how this all integrates into configuration\n",
    "            * EXIII) In Real Life\n",
    "                * Society is formal system, where Money could be seen as a token\n",
    "                * Tokens differ; You can do more things with a loonie than a quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Cognition in Cognitive Science ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Computer\n",
    "    * Informal, automatic system\n",
    "        * Tokens, rules operate in terms of the configuration of the tokens\n",
    "        * Type of tokens: how can they follow the rules\n",
    "    * Propose a realisation\n",
    "        * Accept a formal system that they are medium independent(not halfway independent)\n",
    "            * They depend on the visible things that are programmed in\n",
    "            * This means as long as the system can reliably determine the reliability of the token and manipulate it, its okay\n",
    "        * Two formal systems can be formally equivalent\n",
    "            * Instances of equivalency\n",
    "                * ex) if this is okay in this move, some other form of that is okay in that move. Football VS Chess\n",
    "            * AI requires multiple realisability → Neuroscience deny it\n",
    "                * Tension in Strong AI vs Neuroscience\n",
    "                * How AI is computation?  How can it be multiple realisable when it isn't formal system\n",
    "                * Capacity of a general problem solver?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Techniques of Computation ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Positive Technique\n",
    "    * Is it possible to guess the correct number correctly?\n",
    "        * Guessing is a positive technique; there is a possibility of guessing the right number.\n",
    "* Reliable Technique\n",
    "    * Same problem as the above?\n",
    "        * Counting one by one \n",
    "    * Reliable technique, you get the right answer for sure if you count one by one\n",
    "* Writing - formal system\n",
    "    * Whenever i am manipulating tokens, I am considering all the rules. \n",
    "    * Read\n",
    "        * I am reading the tokens and identifying them correctly after manipulating them.\n",
    "        * Therefore, this system is a cycle, and therefore a formal system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System of a Formal System ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Digital system\n",
    "    * Positive, reliable techniques for producing and re-identifying the configuration of tokens of some pre-specified set of types. (Read cycles)\n",
    "    * Why does it have to be digital?\n",
    "        * The self containism of the self-formal system will be in the core\n",
    "            * If this doesn't happen?\n",
    "                * The self-containism will break down\n",
    "        * Shakespearean chronic is digital\n",
    "            * A random face paint isn't\n",
    "            * We decided that a historical property will be defined. so we can’t manipulate tokens to get a formal equivalent of such.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haugnite’s finite playability(rules) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* “The rest of the world does not follow rules”\n",
    "    * “Living things do?”\n",
    "    * Strong AI - How machines follows rules without the homuncular fallacy\n",
    "    * Rule following -> Describe the behaviour of the chair\n",
    "        * The chair isn't following the rules?\n",
    "        * No..?\n",
    "    * I can use calculus to describe solar system\n",
    "        * Solar system isn't doing calculus? No\n",
    "    * Rule following → Rule describing but without homunculus fallacy\n",
    "* Any complex rule following breaks down into primitive rule following\n",
    "    * This leads to decomposition into primitive algorithms.\n",
    "    * Primitive operators follow primitive rules\n",
    "        * Built in, does it mindlessly?\n",
    "    * Idea of the evolutions can produce chronological machines by doing primitive operations following primitive rules\n",
    "    * Could i do all these manners i a complex manner?\n",
    "    * Could we do this in a machine?\n",
    "        * Yes\n",
    "    * Formal system\n",
    "        * Analyse into primitive algorithm\n",
    "            * Primitive algorithm \n",
    "                * Primitive operators following primitive rules\n",
    "        * Formalise\n",
    "            * How does this function in a formal system?\n",
    "        * Mechanise\n",
    "            * Present this in a machine\n",
    "        * It satisfies the naturalistic imperative\n",
    "            * Construct has a powerful plausibility\n",
    "            * Decompose intelligence into an army of idiots\n",
    "        * Is the machine an intelligence algorithm?\n",
    "            * The chess programme could be completely decomposed but the program is playing chess heuristically(algorithmically it will explode)\n",
    "        * Logic is the syntactic relations with tokens\n",
    "            * This is why reason and logic is the same thing, not a synonym of rational\n",
    "            * Logic can't tell if the conclusion is true or false\n",
    "                * Logic can only tell IF the premises are true, the conclusion will be true OR false\n",
    "        * Identity of machine\n",
    "            * A machine is the same kind of thing as an organism\n",
    "                * We need more identity for the machine\n",
    "                * Just because we are able to manipulate tokens does not mean we have constructed a mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolving the Relevance Problem: Syntactic VS Semantic ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If relevance isn't something not capturable in formal system, we cannot connect tokens into real life\n",
    "    * We can't capture central properties of cognition without relevance formalisation\n",
    "        * Formalise relevance → cannot mechanise computation\n",
    "        * Relevance might not be a formalisable thing\n",
    "        * Strong AI with computational systems might not be possible without this.\n",
    "    * Idealisation\n",
    "        * Independent variable vs dependent\n",
    "            * Remove the irrelevant factors causing a situation\n",
    "            * The more idealisation, the more experiment looses ecological fluidity\n",
    "                * Loses the similarity to the world\n",
    "            * We need to find a way to maintain ecological fluidity with idealisation.\n",
    "            * Must be able to scale up to the real world\n",
    "        * Winograd - SHRDLU\n",
    "            * By IBM HAL\n",
    "            * The microworld which you had very limited features of the environment\n",
    "                * He moved around this virtual world\n",
    "                * The way how succeeded by keeping track of every single object and environment in this small world\n",
    "                    * This was possible because the environment was small.\n",
    "            * Does not give us a clue how to to address problems of making real AI\n",
    "            * Contextual sensitivity\n",
    "                * How does the system read relevant system to bare?\n",
    "        * Stereotype\n",
    "            * Depends how well defined the problem is\n",
    "                * Well defined→ no stereotype\n",
    "                * Real world problems are gonna trigger a lot of stereotypes\n",
    "                    * If they are ambiguous, ill defined problem → creates a miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microworld ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Defeated GPS → Complexity of environment\n",
    "    * Science: Idealisation(simplification of the natural world)\n",
    "        * Did not give us principle answers to the simplified world\n",
    "        * Move away of stereotypes\n",
    "            * How this relevance is resolved\n",
    "        * Additional new things with stereotypes\n",
    "            * Prototype theory could simplify ideas\n",
    "            * Where to stop the search?\n",
    "* Proposal of strong AI by formal systems\n",
    "    * Zero win on this problem\n",
    "    * Hebert Fribest\n",
    "        * Frame problem\n",
    "            * Technical: how to create logic to compute programming could control change without identities being messed up\n",
    "        * Relevance Problem\n",
    "            * This is not a formal property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks and AI ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Problem is a formalisable property\n",
    "    * Late 80s~early 90s\n",
    "        * Processing neural networks and connectionism\n",
    "            * GOFI failed because it understood cognition as language-like\n",
    "            * Thinking is like speaking, which is not.\n",
    "            * The fact of this does not lead to implying in deductive inference that cognition is not language-like\n",
    "                * GOFI fails because it is fundamentally failing since it does not align with Hobbesian computation.\n",
    "            * Cognition itself is language like but the much we deviate from that we understand the language process, which both aren't integratable together.\n",
    "    * History of neuronetwork → Perceptrons are impressive machines\n",
    "        * Prove that these cannot do psychological functions\n",
    "            * Behaviours are understood as complex manipulation of stimulus and response\n",
    "                * By formalise/analyse/mechaise, this is not doable with Perceptrons\n",
    "            * Adding and intervening layers between stimulus and response would not alleviate the problem in neural networks\n",
    "                * People disagreed with this at first\n",
    "                * A group of people challenged, saying adding layers will change up things.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectionism ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dont model your proposed stimulation on language\n",
    "* Multiple realisability\n",
    "    * Two hardwares being mutually implementable\n",
    "        * It does limit how broadly this could be applied.\n",
    "        * One thing still not clear(theoretical) in a strong AI sampling\n",
    "            * What do the nodes and lines correspond to?\n",
    "            * The nodes to not correspond to neurons, it corresponds to groups of neurons\n",
    "                * Do not behave as nodes behave\n",
    "        * What is modeled in a neuronetwork? It is not clear.\n",
    "            * There is no clear answer what the networks are modelling in the brain or corresponding to in the brain\n",
    "            * So, the issue of multiple realisability is not resolved.\n",
    "            * These network are lacking meaning of functional elements in the brain.\n",
    "                * No network\n",
    "                * There were few attempts to build this.\n",
    "            * Neural Networks and the brain are very loose, and unclear..(extended in bullet point below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspirations and properites of the Neural Network ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One neuron could inhibit another neuron, and they have a causal relationship which other\n",
    "    * Connected, and they cause excitation and inhibition\n",
    "    * Valence +-\n",
    "* Signal Strength\n",
    "    * How much one neuron is firing for neural communication?\n",
    "    * How frequently do neurons fire?\n",
    "* Emergency mechanism\n",
    "    * The attachment works like the emergency mechanism\n",
    "    * “I shouldn't do this” isn’t very powerful\n",
    "    * Attachment\n",
    "        * Death, Divorce, etc…\n",
    "* Connection weight\n",
    "    * Diameter of the pipe\n",
    "* Take these three non-linguistic variables and build machines that can solve problems, to cover psychological problems such as implication..etc\n",
    "    * A affects other nodes → Activation through the neural networks\n",
    "* How many different functions can you implement?(how many kinds?)\n",
    "* Neurons are calculating systems in the brain?\n",
    "    * Neurons are not computations, it is only done to run on a computer.\n",
    "    * Therefore, the nodes are not summing numbers, it is just a mechanical process which we have not figured out the big picture of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of Neural Networking ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multiple simultaneous constraint problems\n",
    "    * Pick up patterns of complex behaviour\n",
    "    * Parallel distributed processing\n",
    "        * “what did you just do?\n",
    "    * Modelling rigorous fashion\n",
    "        * Know how what we rely upon with this knowhow\n",
    "        * They present a genuine standard of GOFI cuz they provide theoretical tools to exemplify exemplifying knowledge\n",
    "* Neuronetwork learning depends on humans\n",
    "    * learning is based on successful learning\n",
    "    * Unsupervised account of plasticity needed\n",
    "* We do not have a complete consensus building of what is successful learning\n",
    "    * Convergence\n",
    "    * Unsupervised plasticity\n",
    "    * Schultz\n",
    "        * Self organisation is a powerful solution to resolve the unsupervised plasticity problem\n",
    "        * How is governing learning?\n",
    "            * Done in a self organising fashion\n",
    "    * Understanding Functioning of the software → algorithmic structure\n",
    "        * If both thr software and hardware are acting in a self-organising manner, there is no distinction between how it is functioning and how it was historically developed\n",
    "            * Intertwined\n",
    "        * Dynamic self organisation\n",
    "* Animal research\n",
    "    * Animals are dealing with fixation..?\n",
    "* No hermeneutics to the dream\n",
    "* Basic function - signal strength, weighting of the connection\n",
    "    * Output signals to its connection\n",
    "* Sampling Bias\n",
    "    * Overfits to the data(patterns of data that does not fit the whole population)\n",
    "* Why do we need Plasticity\n",
    "    * Intelligent agent that purposely alters the architecture causes homoncularity so we need plasticity(unsupervised learning) for strong AI.\n",
    "        * Takers with the architecture\n",
    "        * Multiple simultaneous constraints\n",
    "        * Parallel Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advent of Neuronetwork Modelling - Unsupervised Learning ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cognition is understood more generally than fundamentally.\n",
    "* Hardware is inherently developmental nature\n",
    "    * It can also self organise\n",
    "* Software System\n",
    "* Hardware System\n",
    "    * New model → Integration of Software and Hardware organisation\n",
    "    * Not a final theory but a gateway to resolve Unsupervised Plasticity\n",
    "    * Explicitly responding to the flaws of GOFI development\n",
    "    * Advance a solution towards unsupervised Plasticity, Critiquing GOFI\n",
    "* 1996\n",
    "    * Cascade Correlation Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
